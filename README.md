A research-grade implementation of a Self-Evolving Temporal Retrieval-Augmented Generation system designed to address outdated knowledge, hallucinations, and static retrieval behavior in Large Language Models (LLMs).

This project introduces time-aware retrieval and a feedback-driven self-evolution mechanism that allows the system to continuously adapt its knowledge base without retraining the underlying language model.

ğŸ“Œ Motivation

Large Language Models are trained on static corpora and therefore struggle with:

Time-sensitive queries

Outdated factual knowledge

Hallucinations caused by stale retrieval

While Retrieval-Augmented Generation (RAG) improves factual grounding, most RAG systems ignore temporal relevance and lack autonomous knowledge adaptation.

This project addresses these gaps by introducing:

Explicit temporal modeling during retrieval

A self-evolving feedback loop that refines retrieval behavior over time

ğŸš€ Key Contributions

Temporal Retrieval
Incorporates document timestamps using decay-based ranking to prioritize recent knowledge.

Self-Evolving Knowledge Base
Updates retrieval behavior using confidence-driven feedback without retraining the LLM.

Multi-Mode Evaluation
Supports baseline RAG, temporal RAG, and self-evolving temporal RAG for fair comparison.

Research-Ready Outputs
Generates reproducible experiments, ablation studies, and analysis figures suitable for academic publication.

ğŸ—ï¸ System Architecture

The system consists of the following major components:

Data Ingestion & Preprocessing

Raw text ingestion from arXiv, Wikipedia, and web sources

Cleaning, chunking, and metadata extraction

Embedding & Indexing

Sentence-level embeddings using transformer encoders

FAISS vector indexing for efficient retrieval

Temporal Retrieval Module

Time-decay weighting integrated with semantic similarity

LLM-Based Generation

Context-aware response generation using retrieved evidence

Self-Evolving Agent

Confidence evaluation

Knowledge reinforcement and update

ğŸ“ Project Structure
self-evolving-temporal-rag/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 # Raw text documents
â”‚   â”œâ”€â”€ embeddings/          # embeddings.npy, texts.json, metadata.json
â”‚   â””â”€â”€ index/               # FAISS index
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ build_embeddings.py  # Build embeddings + metadata
â”‚   â”œâ”€â”€ build_index.py       # Create FAISS index
â”‚   â”œâ”€â”€ run_pipeline.py      # Run baseline / temporal / evolving RAG
â”‚   â””â”€â”€ evaluate.py          # Generate figures (Fig 6â€“13)
â”‚
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ baseline/
â”‚   â”œâ”€â”€ temporal/
â”‚   â”œâ”€â”€ self_evolving/
â”‚   â””â”€â”€ results/             # All plots and metrics
â”‚
â”œâ”€â”€ logs/                    # Retrieval & evolution logs
â”œâ”€â”€ paper/                   # LaTeX sections for research paper
â”œâ”€â”€ docs/                    # Diagrams and methodology
â””â”€â”€ README.md

ğŸ“Š Experimental Results

The system generates the following research figures:

Figure	Description
Fig. 6	Baseline vs Temporal vs Self-Evolving Retrieval
Fig. 7	Hallucination Reduction
Fig. 8	Confidence Score Distribution
Fig. 9	Ranking Change due to Temporal Logic
Fig. 10	Accuracy vs Latency Trade-off
Fig. 11	Ablation Study
Fig. 12	Knowledge Base Growth
Fig. 13	Failure Case Analysis

All figures are saved under:

experiments/results/

âš™ï¸ Setup Instructions
1ï¸âƒ£ Create Virtual Environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

2ï¸âƒ£ Install Dependencies
pip install -r requirements.txt


On Windows, FAISS must be installed as:

pip install faiss-cpu

â–¶ï¸ Running the Pipeline
Step 1: Build Embeddings
python scripts/build_embeddings.py

Step 2: Build FAISS Index
python scripts/build_index.py

Step 3: Run Retrieval Pipeline
python scripts/run_pipeline.py --mode baseline
python scripts/run_pipeline.py --mode temporal
python scripts/run_pipeline.py --mode self_evolving

Step 4: Generate Evaluation Figures
python scripts/evaluate.py

ğŸ§ª Evaluation Metrics

Retrieval Accuracy

Hallucination Rate

Confidence Score

Temporal Freshness

Latency vs Accuracy

Knowledge Base Growth

âš ï¸ Limitations

Manual dataset curation

Dependency on timestamp metadata

Offline evaluation (no real-time ingestion)

Text-only knowledge sources

These limitations are discussed in detail in the accompanying research paper.

ğŸ”® Future Extensions

Real-time web ingestion

Temporal embedding learning

Multimodal RAG (text + images + tables)

Reinforcement learning-based evolution

Human-in-the-loop validation

ğŸ“„ Research Paper

This repository accompanies the research paper:

â€œA Self-Evolving Temporal Retrieval-Augmented Generation System for Time-Sensitive Knowledge Accessâ€

All LaTeX sources are available in the paper/ directory.

ğŸ‘¤ Author

Swarajaya Singh Sawant
Department of Computer Science
Dehradun, India